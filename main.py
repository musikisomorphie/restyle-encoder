#!/usr/bin/env python3

import sys
import time
import torch
import logging
import random
import torchvision.utils as tv_utils
import numpy as np
from argparse import Namespace
from pathlib import Path

from args import parse_args
from models.psp import pSp
from configs import data_configs
from torch.utils.data import DataLoader
from datasets.images_dataset import ImagesDataset
from scipy.linalg import svd


def configure_datasets(args):
    if args.data_name not in data_configs.DATASETS.keys():
        raise Exception(
            '{} is not a valid dataset_type'.format(args.data_name))
    print('Loading dataset for {}'.format(args.data_name))
    dataset_args = data_configs.DATASETS[args.data_name]
    transforms_dict = dataset_args['transforms'](args).get_transforms()
    test_dataset = ImagesDataset(source_root=dataset_args['test_source_root'],
                                 target_root=dataset_args['test_target_root'],
                                 source_transform=transforms_dict['transform_source'],
                                 target_transform=transforms_dict['transform_test'],
                                 opts=args)
    print("Number of testing samples: {}".format(len(test_dataset)))
    return test_dataset


def setup_logg(args):
    """ configure the logging document that records the 
    critical information during training and create 
    args.save_dir parameter used for saving visual and training
    results.

    Args:
        args: arguments that are implemented in args.py file 
            and determined in the training command,
            such as data_type, split_scheme, etc. 
    """

    args.save_dir = Path(args.save_path) / args.data_name
    args.save_dir.mkdir(parents=True, exist_ok=True)
    head = '{asctime}:{levelname}: {message}'
    handlers = [logging.StreamHandler(sys.stderr)]
    handlers.append(logging.FileHandler(str(args.save_dir / 'log'),
                                        mode='w'))
    logging.basicConfig(level=logging.INFO,
                        format=head,
                        style='{', handlers=handlers)
    logging.info('Start with arguments {}'.format(args))


def setup_seed(seed):
    """ 
    Args:
        seed: the seed for reproducible randomization. 
    """

    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)


def get_model(ckpt_path):
    restyle_ckpt = torch.load(ckpt_path, map_location='cpu')
    restyle_opts = restyle_ckpt['opts']
    restyle_opts.update({'checkpoint_path': ckpt_path})
    restyle_opts = Namespace(**restyle_opts)
    logging.info('Restyle auto-encoder opts:\n{}'.format(str(restyle_opts)))

    restyle = pSp(restyle_opts).cuda().eval()
    logging.info('Restyle auto-encoder with loaded weights:\n{}'.
                 format(str(restyle)))

    return restyle


def get_avgim(restyle):
    """ Compuate the average image that is used 
    to append to the input image. The code snippet 
    is copied from coach_restyle_psp.py

    Args:
        restyle: the trained restyle encoder 
            and stylgan decoder
    """

    restyle.latent_avg = restyle.decoder.mean_latent(int(1e5))[0]
    restyle.latent_avg = restyle.latent_avg.detach()

    avg_img = restyle(restyle.latent_avg.unsqueeze(0),
                      input_code=True,
                      randomize_noise=False,
                      return_latents=False,
                      average_code=True)[0]
    return avg_img.detach()


@torch.no_grad()
def recon(dt_load,
          restyle,
          avg_img,
          save_dir=None):
    """ Reconstruct the input image with Restyle auto-encoder.

    Args:
        save_dir: the folder path storing the fake image
        data_loader: the train, val, test (ood_test) or id_test data loader 
            called via wilds api
        restyle: the trained Restyle auto-encoder
        avg_img: the average image that appends to the input image of
            Restyle auto-encoder
    """

    img0, rec0, total = None, None, None
    for dt_id, (X, _) in enumerate(dt_load):
        X = X[:, :3].cuda()
        avg = avg_img.unsqueeze(0)
        avg = avg.repeat(X.shape[0], 1, 1, 1)
        avg = avg.float().to(X)
        # concatenate the average image to input
        X_inp = torch.cat([X, avg], dim=1)
        # output styles (codes) and noises
        codes = restyle.encoder(X_inp)
        # the same latent_avg generated by
        # restyle.decoder.mean_latent(int(1e5))[0],
        # which is also used for generate avg_img.
        latent_avg = restyle.latent_avg.repeat(codes.shape[0], 1, 1)

        
        if dt_id == 0:
            img0 = X
            rec0 = (codes + latent_avg.to(codes))
            cod0 = rec0.clone().view(rec0.shape[0], -1)
            cod0 = cod0.cpu().numpy().astype(np.float64)
            print(img0.shape, rec0.shape)
        codes = codes + latent_avg.to(codes)
        codes = codes.view(codes.shape[0], -1)
        if total is None:
            total = codes.T @ codes
        else:
            total += codes.T @ codes
       

    print('compute eigenvalue')
    total = total.cpu().numpy().astype(np.float64) / (len(dt_load))
    total = np.asfortranarray(total)
    ortho, d = svd(total, overwrite_a=True)[:2]

    codes = ortho.T @ cod0.T
    print(codes[0])
    codes[0] *= 1.5
    codes = (ortho @ codes).T
    print(np.max(np.abs(codes[:] - cod0[:])))
    codes = torch.from_numpy(codes.astype(np.float32)).cuda()
    codes = codes.view(cod0.shape[0], -1, 512)
    print('eigenvalue done')

    if save_dir is not None:
        # X_out is the reconstructed image
        X_man = restyle.decoder([codes],
                                input_is_latent=True)[0]
        # Since the input image is normalized by (image - 0.5) / 0.5,
        # now we need to convert the pixel interval back to [0, 1]
        X_man = (X_man + 1) / 2
        X_man[X_man < 0] = 0
        X_man[X_man > 1] = 1

        # X_out is the reconstructed image
        X_rec = restyle.decoder([rec0],
                                input_is_latent=True)[0]
        # Since the input image is normalized by (image - 0.5) / 0.5,
        # now we need to convert the pixel interval back to [0, 1]
        X_rec = (X_rec + 1) / 2
        X_rec[X_rec < 0] = 0
        X_rec[X_rec > 1] = 1

        X = img0
        X = (X + 1) / 2
        X[X < 0] = 0
        X[X > 1] = 1
        # Visually compare the reconstructed and gt images side by side
        X_merge = torch.zeros([X.shape[0] * 3,
                               X.shape[1],
                               X.shape[2],
                               X.shape[3]]).to(X)

        bb_col = [1, 0, 0]
        bb_len = 4
        # add red bbox to gt image
        for i in range(3):
            X[:, i, :bb_len, :] = bb_col[i]
            X[:, i, -bb_len:, :] = bb_col[i]
            X[:, i, :, :bb_len] = bb_col[i]
            X[:, i, :, -bb_len:] = bb_col[i]

        X_merge[::3] = X_man
        X_merge[1::3] = X_rec
        X_merge[2::3] = X

        filename = Path(save_dir) / \
            '{}.jpg'.format(dt_id)
        tv_utils.save_image(X_merge.cpu().float(),
                            str(filename),
                            nrow=9,
                            padding=2)
        print(str(filename))


@torch.no_grad()
def synth(batch_size, restyle, save_dir=None):
    """ Synthesize fake images with StyleGAN decoder,
    where the input are random gaussian noise.

    Args:
        save_dir: the folder path storing the fake image
        restyle: the trained Restyle auto-encoder
    """

    latent = torch.randn(batch_size, 512).cuda()
    fake = restyle.decoder([latent])[0]
    fake = (fake + 1) / 2
    fake[fake < 0] = 0
    fake[fake > 1] = 1
    if save_dir is not None:
        filename = Path(save_dir) / 'fake.jpg'
        tv_utils.save_image(fake.cpu().float(),
                            str(filename),
                            nrow=8,
                            padding=2)
    return fake


def main(args):
    """ The main function running the experiments 
    reported in the paper.
    if args.mode == 'recon', save the image reconstruction results
        achieved by Restyle auto-encoder
    elif args.mode == 'synth', save the images synthesized with 
        StyleGAN decoder.

    Args:
        args: critical parameters specified in args.py.
    """

    # load the data via wilds api
    test_dataset = configure_datasets(args)
    dataloader = DataLoader(test_dataset,
                            batch_size=args.n_eval,
                            shuffle=True,
                            num_workers=args.n_work,
                            drop_last=False)

    # initialize the restyle model parameters and weights
    restyle = get_model(str(args.ckpt_path))
    avg_img = get_avgim(restyle)

    if args.mode == 'recon':
        recon(dataloader, restyle, avg_img, args.save_dir)
    elif args.mode == 'synth':
        synth(args.n_eval, restyle, args.save_dir)
    else:
        assert 0


if __name__ == '__main__':
    args = parse_args()
    setup_seed(args.seed)
    setup_logg(args)
    main(args)
